optimizer:
  name: "hybrid"
  lr: 1e-3
  betas: [0.0, 0.9, 0.99]
  weight_decay: 0.0
  eps: 1e-6

training:
  batch_size: 32
  epochs: 10
  log_interval: 100

model:
  name: "simple_cnn"  # Placeholder for future LLM config
